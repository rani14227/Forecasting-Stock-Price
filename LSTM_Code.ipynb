{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827ba62-b69a-47b7-a896-b8f108ba083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly.\"\"\"\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     fig_close = go.Figure(go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price'))\n",
    "#     fig_close.update_layout(\n",
    "#         title='Close Price Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Close Price'\n",
    "#     )\n",
    "#     fig_close.show()\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     fig_open = go.Figure(go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price'))\n",
    "#     fig_open.update_layout(\n",
    "#         title='Open Price Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Open Price'\n",
    "#     )\n",
    "#     fig_open.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9324c6-3017-49df-98f1-7555e309e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices with Plotly.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price')\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', yaxis='y2')\n",
    "    \n",
    "#     fig.add_trace(trace_close, secondary_y=False)\n",
    "#     fig.add_trace(trace_open, secondary_y=True)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Stock Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Close Price',\n",
    "#         yaxis2_title='Open Price',\n",
    "#         yaxis=dict(range=[data['Close'].min(), data['Close'].max()]),\n",
    "#         yaxis2=dict(range=[data['Open'].min(), data['Open'].max()]),\n",
    "#     )\n",
    "    \n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f047a0c-3123-4631-85b6-8c93e29f3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices with Plotly.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price')\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', yaxis='y2')\n",
    "    \n",
    "#     fig.add_trace(trace_close, secondary_y=False)\n",
    "#     fig.add_trace(trace_open, secondary_y=True)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Stock Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Close Price',\n",
    "#         yaxis2_title='Open Price'\n",
    "#     )\n",
    "    \n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d4979-c061-417e-96e1-7d435c104eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the original stock data.\"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "    \n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     plt.plot(data['Close'], label='Close Price')\n",
    "#     plt.title('Stock Price Over Time')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb3a5c-a6fc-4b5a-b88a-c7147a8019d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# import logging\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# class DataPreprocessor:\n",
    "#     def __init__(self, feature_scaling='minmax'):\n",
    "#         \"\"\"\n",
    "#         Initialize DataPreprocessor with specified feature scaling.\n",
    "#         \"\"\"\n",
    "#         self.scaler = MinMaxScaler() if feature_scaling == 'minmax' else StandardScaler()\n",
    "#         logging.info(f\"Using {feature_scaling} scaling for features.\")\n",
    "    \n",
    "#     def preprocess(self, data: pd.DataFrame) -> tuple:\n",
    "#         \"\"\"\n",
    "#         Preprocess stock data for LSTM model.\n",
    "        \n",
    "#         Args:\n",
    "#             data (pd.DataFrame): Raw stock data.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: Scaled features and original scaler instance.\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             logging.info(\"Preprocessing stock data.\")\n",
    "            \n",
    "#             # Extract the 'Close' price series\n",
    "#             prices = data[['Close']].values\n",
    "            \n",
    "#             # Fit and transform the price data\n",
    "#             scaled_prices = self.scaler.fit_transform(prices)\n",
    "            \n",
    "#             # Check for data transformation\n",
    "#             logging.info(\"Data has been scaled for LSTM input.\")\n",
    "            \n",
    "#             return scaled_prices, self.scaler\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error in preprocessing: {e}\")\n",
    "#             raise\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"\n",
    "#     Plot the 'Close' price to visualize the data.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): DataFrame containing stock data.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     plt.plot(data['Close'], label='Close Price')\n",
    "#     plt.title('Stock Price Over Time')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def main() -> pd.DataFrame:\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "#     stock_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "#     return stock_data\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == '__main__':\n",
    "#     raw_data = main()  # Get raw stock data\n",
    "\n",
    "#     # Visualize raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Initialize DataPreprocessor\n",
    "#     data_preprocessor = DataPreprocessor(feature_scaling='minmax')\n",
    "    \n",
    "#     # Preprocess data for LSTM\n",
    "#     scaled_data, scaler = data_preprocessor.preprocess(raw_data)\n",
    "\n",
    "#     # Example: printing first few scaled values\n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023eca6-0fbe-441f-ae70-d155658f43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     # Summary report\n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def data_summary(data: pd.DataFrame):\n",
    "#     \"\"\"Provides summary statistics of the dataset.\"\"\"\n",
    "#     logging.info(\"Generating summary statistics for the dataset.\")\n",
    "#     summary = data.describe()\n",
    "#     logging.info(f\"Summary statistics:\\n{summary}\")\n",
    "#     return summary\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly, side by side.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Generate and log data summary\n",
    "#     summary = data_summary(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f25e05-cb3d-4010-902a-3b14f79c3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\n",
    "\n",
    "#     Args:\n",
    "#         ticker (str): Stock ticker symbol.\n",
    "#         start_date (str): Start date for data download.\n",
    "#         end_date (str): End date for data download.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Stock data indexed by date.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker} from {start_date} to {end_date}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except (ValueError, ConnectionError) as e:\n",
    "#         logging.error(f\"Error occurred while downloading stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates in the dataset.\n",
    "\n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Input data to check.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Missing values and duplicate counts.\n",
    "#     \"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\n",
    "\n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Raw stock data.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Scaled features and the scaler instance.\n",
    "#     \"\"\"\n",
    "#     logging.info(\"Starting preprocessing of stock data.\")\n",
    "    \n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing is complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices side by side with Plotly.\n",
    "\n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Processed stock data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main function to run the stock data download, quality check, visualization, and preprocessing.\"\"\"\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13279500-d345-4423-a695-5a957ba0fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from datetime import datetime\n",
    "\n",
    "# def feature_selection(data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Select relevant features for LSTM prediction.\"\"\"\n",
    "#     selected_features = data[['Close', 'SMA_10', 'EMA_10']]\n",
    "#     logging.info(\"Selected features: 'Close', 'SMA_10', 'EMA_10'\")\n",
    "#     return selected_features\n",
    "\n",
    "# def normalize_features(features: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Normalize features using MinMaxScaler.\"\"\"\n",
    "#     scaler = MinMaxScaler()\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "#     logging.info(\"Normalized features using MinMaxScaler.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def create_sequences(data: np.ndarray, sequence_length: int) -> tuple:\n",
    "#     \"\"\"Create sequences for LSTM model.\"\"\"\n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data)):\n",
    "#         X.append(data[i-sequence_length:i])\n",
    "#         y.append(data[i, 0])  # Predicting 'Close' price\n",
    "    \n",
    "#     X, y = np.array(X), np.array(y)\n",
    "#     logging.info(f\"Created sequences with length: {sequence_length}\")\n",
    "#     return X, y\n",
    "\n",
    "# def main_lstm_preparation():\n",
    "#     \"\"\"Main function for feature selection, normalization, and sequence creation.\"\"\"\n",
    "#     # Use the preprocessed data from Chunk 1\n",
    "#     raw_data = main()\n",
    "    \n",
    "#     # Select relevant features\n",
    "#     features = feature_selection(raw_data)\n",
    "    \n",
    "#     # Normalize features\n",
    "#     scaled_data, scaler = normalize_features(features)\n",
    "    \n",
    "#     # Define sequence length\n",
    "#     sequence_length = 60  # Example length\n",
    "    \n",
    "#     # Create sequences\n",
    "#     X, y = create_sequences(scaled_data, sequence_length)\n",
    "    \n",
    "#     # Split data into train and test based on specific dates\n",
    "#     train_end_date = datetime(2023, 3, 31)\n",
    "#     test_start_date = datetime(2023, 4, 1)\n",
    "    \n",
    "#     # Train data indices\n",
    "#     train_indices = raw_data.index < train_end_date\n",
    "    \n",
    "#     # Test data indices\n",
    "#     test_indices = raw_data.index >= test_start_date\n",
    "    \n",
    "#     X_train, X_test = X[train_indices], X[test_indices]\n",
    "#     y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "#     logging.info(f\"Training data: {X_train.shape[0]} samples\")\n",
    "#     logging.info(f\"Testing data: {X_test.shape[0]} samples\")\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = main_lstm_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9b31c-1a8e-49d8-bf49-16a55ffb80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def feature_selection(data: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Select relevant features for LSTM prediction.\"\"\"\n",
    "#     # Assuming 'Close', 'SMA_10', and 'EMA_10' are relevant features\n",
    "#     selected_features = data[['Close', 'SMA_10', 'EMA_10']]\n",
    "#     logging.info(\"Selected features: 'Close', 'SMA_10', 'EMA_10'\")\n",
    "#     return selected_features\n",
    "\n",
    "# def normalize_features(features: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Normalize features using MinMaxScaler.\"\"\"\n",
    "#     scaler = MinMaxScaler()\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "#     logging.info(\"Normalized features using MinMaxScaler.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def create_sequences(data: np.ndarray, sequence_length: int) -> tuple:\n",
    "#     \"\"\"Create sequences for LSTM model.\"\"\"\n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data)):\n",
    "#         X.append(data[i-sequence_length:i])\n",
    "#         y.append(data[i, 0])  # Predicting 'Close' price\n",
    "    \n",
    "#     X, y = np.array(X), np.array(y)\n",
    "#     logging.info(f\"Created sequences with length: {sequence_length}\")\n",
    "#     return X, y\n",
    "\n",
    "# def main_lstm_preparation():\n",
    "#     \"\"\"Main function for feature selection, normalization, and sequence creation.\"\"\"\n",
    "#     # Use the preprocessed data from Chunk 1\n",
    "#     raw_data = main()\n",
    "    \n",
    "#     # Select relevant features\n",
    "#     features = feature_selection(raw_data)\n",
    "    \n",
    "#     # Normalize features\n",
    "#     scaled_data, scaler = normalize_features(features)\n",
    "    \n",
    "#     # Define sequence length\n",
    "#     sequence_length = 60  # Example length\n",
    "    \n",
    "#     # Create sequences\n",
    "#     X, y = create_sequences(scaled_data, sequence_length)\n",
    "    \n",
    "#     # Optionally split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#     logging.info(\"Split the data into training and testing sets.\")\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = main_lstm_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b66737-4fa4-4787-a9c3-7d406018cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): The stock data to split.\n",
    "#         train_start (str): Start date for the training set.\n",
    "#         train_end (str): End date for the training set.\n",
    "#         test_start (str): Start date for the testing set.\n",
    "#         test_end (str): End date for the testing set.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: DataFrames for training and testing sets.\n",
    "#     \"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int):\n",
    "#     \"\"\"Normalize features and create sequences for LSTM.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): DataFrame containing the features to be scaled.\n",
    "#         sequence_length (int): The number of previous days to consider for each sample.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: numpy arrays for input sequences, target values, and scaler.\n",
    "#     \"\"\"\n",
    "#     # Initialize the MinMaxScaler\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     # Scale the features\n",
    "#     data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     # Create sequences of the specified length\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y), scaler\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\n",
    "    \n",
    "#     Downloads and preprocesses the stock data, then splits it into training and testing sets.\n",
    "#     The data is normalized and sequences are created for the LSTM model.\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: Prepared data for training and testing (X_train, X_test, y_train, y_test) and scaler.\n",
    "#     \"\"\"\n",
    "#     # Assuming download_stock_data and preprocess_data are defined in Chunk 1\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data (replace with the correct function)\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data (replace with the correct function)\n",
    "#     preprocessed_data, _ = preprocess_data(raw_data)\n",
    "    \n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train, scaler = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test, _ = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b8582-727c-4248-bfa1-f7a178d4bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\n",
    "    \n",
    "#     Args:\n",
    "#         ticker (str): Stock ticker symbol.\n",
    "#         start_date (str): Start date for the data.\n",
    "#         end_date (str): End date for the data.\n",
    "    \n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with the downloaded stock data.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates in the data.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): DataFrame to check.\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: Missing values and duplicate counts.\n",
    "#     \"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for the LSTM model by adding features and scaling.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): Raw stock data.\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: Scaled features and scaler instance.\n",
    "#     \"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices with Plotly.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): DataFrame with the stock data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main function to download data, check quality, visualize and preprocess.\"\"\"\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8984d5a-d58d-47d0-9635-88d7bf64d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): The stock data to split.\n",
    "#         train_start (str): Start date for the training set.\n",
    "#         train_end (str): End date for the training set.\n",
    "#         test_start (str): Start date for the testing set.\n",
    "#         test_end (str): End date for the testing set.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: DataFrames for training and testing sets.\n",
    "#     \"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int):\n",
    "#     \"\"\"Normalize features and create sequences for LSTM.\n",
    "    \n",
    "#     Args:\n",
    "#         data (pd.DataFrame): DataFrame containing the features to be scaled.\n",
    "#         sequence_length (int): The number of previous days to consider for each sample.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: numpy arrays for input sequences, target values, and scaler.\n",
    "#     \"\"\"\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y), scaler\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\n",
    "    \n",
    "#     Downloads and preprocesses the stock data, then splits it into training and testing sets.\n",
    "#     The data is normalized and sequences are created for the LSTM model.\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: Prepared data for training and testing (X_train, X_test, y_train, y_test) and scaler.\n",
    "#     \"\"\"\n",
    "#     # Assuming download_stock_data and preprocess_data are defined in Chunk 1\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data (replace with the correct function)\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data (replace with the correct function)\n",
    "#     _, scaler = preprocess_data(raw_data)  # Keep scaler only for transforming\n",
    "\n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train, _ = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test, _ = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ebe23-2ecb-4bee-ab81-9ff952f8a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname=s - %(message=s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     # Summary report\n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly, side by side.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f22adb-1f6d-4134-9646-95cf77a8f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         if data.empty:\n",
    "#             raise ValueError(\"Downloaded data is empty.\")\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     # Summary report\n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering: Add SMA, EMA, and additional lag features\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "#     data['Lag_Close_3'] = data['Close'].shift(3)\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly, side by side.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900a696-f4ae-46e2-ada6-dd5986f82ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int):\n",
    "#     \"\"\"Normalize features and create sequences.\"\"\"\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y), scaler\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\"\"\"\n",
    "#     # Assuming download_stock_data and preprocess_data are defined in Chunk 1\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data (replace with the correct function)\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data (replace with the correct function)\n",
    "#     preprocessed_data, _ = preprocess_data(raw_data)\n",
    "    \n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train, scaler = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test, _ = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10']], sequence_length)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a4068-53c1-4c35-bf28-e0e1656b2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message=s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int, scaler: MinMaxScaler):\n",
    "#     \"\"\"Normalize features and create sequences using the specified scaler.\"\"\"\n",
    "#     # Scale the features using the provided scaler\n",
    "#     data_scaled = scaler.transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\"\"\"\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     preprocessed_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bc2ef-d80b-4f14-b668-6131f957c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the predictions and actual data.\"\"\"\n",
    "#     # Extracting the 'Close' column index\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     plt.plot(y_test_inv, color='blue', label='Actual Prices')\n",
    "#     plt.plot(predictions_inv, color='red', label='Predicted Prices')\n",
    "#     plt.title('Stock Price Prediction')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Stock Price')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd3d36-c6e0-4507-9378-55630246376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the predictions and actual data using Plotly.\"\"\"\n",
    "#     # Extracting the 'Close' column index\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     # Create a Plotly graph\n",
    "#     fig = make_subplots(rows=1, cols=1)\n",
    "#     fig.add_trace(go.Scatter(x=np.arange(len(y_test_inv)), y=y_test_inv.flatten(), mode='lines', name='Actual Prices'))\n",
    "#     fig.add_trace(go.Scatter(x=np.arange(len(predictions_inv)), y=predictions_inv.flatten(), mode='lines', name='Forecast Prices'))\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title=\"Stock Price Forecasting\",\n",
    "#         xaxis_title=\"Time\",\n",
    "#         yaxis_title=\"Stock Price\",\n",
    "#         legend_title=\"Legend\",\n",
    "#         font=dict(\n",
    "#             family=\"Courier New, monospace\",\n",
    "#             size=18,\n",
    "#             color=\"RebeccaPurple\"\n",
    "#         )\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# # Call the visualization function with the test and prediction data\n",
    "# postprocess_and_visualize(y_test, predictions, scaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac276986-24b6-4e4e-9d68-4bc33113bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the predictions and actual data.\"\"\"\n",
    "#     # Extracting the 'Close' column index\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(14, 7))\n",
    "#     plt.plot(y_test_inv, color='blue', label='Actual Prices')\n",
    "#     plt.plot(predictions_inv, color='red', label='Predicted Prices')\n",
    "#     plt.title('Stock Price Prediction')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel('Stock Price')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler)\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0e671-dd8d-4304-baa7-8d73a8dd8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv, start_date, end_date, forecast_start_date, forecast_end_date):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "\n",
    "#     # Generate timeframes for the x-axis\n",
    "#     actual_timeframe = pd.date_range(start_date, end_date, periods=len(y_test_inv))\n",
    "#     forecast_timeframe = pd.date_range(forecast_start_date, forecast_end_date, periods=len(predictions_inv))\n",
    "    \n",
    "#     fig.update_traces(x=actual_timeframe.tolist() + forecast_timeframe.tolist())\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler, start_date, end_date, forecast_start_date, forecast_end_date):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv, start_date, end_date, forecast_start_date, forecast_end_date)\n",
    "\n",
    "# # Adjust the timeframes based on your data\n",
    "# start_date = '2019-04-01'\n",
    "# end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# forecast_end_date = '2025-03-31'\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler, start_date, end_date, forecast_start_date, forecast_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef34918-8a62-4d64-a99b-6f894a47c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_timeframe, y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(x=forecast_timeframe, y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler, start_date, end_date, forecast_start_date, forecast_end_date):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     # Generate timeframes for the x-axis\n",
    "#     actual_timeframe = pd.date_range(start_date, end_date, periods=len(y_test_inv))\n",
    "#     forecast_timeframe = pd.date_range(forecast_start_date, forecast_end_date, periods=len(predictions_inv))\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe)\n",
    "\n",
    "# # Adjust the timeframes based on your data\n",
    "# start_date = '2019-04-01'\n",
    "# end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# forecast_end_date = '2025-03-31'\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler, start_date, end_date, forecast_start_date, forecast_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d5fcb-f4ad-4e79-a74d-5ec006790d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_timeframe, y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(x=forecast_timeframe, y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler, actual_start_date, actual_end_date, forecast_start_date, forecast_end_date):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     # Generate timeframes for the x-axis\n",
    "#     actual_timeframe = pd.date_range(actual_start_date, actual_end_date, periods=len(y_test_inv))\n",
    "#     forecast_timeframe = pd.date_range(forecast_start_date, forecast_end_date, periods=len(predictions_inv))\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe)\n",
    "\n",
    "# # Adjust the timeframes based on your data\n",
    "# actual_start_date = '2019-04-01'\n",
    "# actual_end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# forecast_end_date = '2025-03-31'\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler, actual_start_date, actual_end_date, forecast_start_date, forecast_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b9f8d-69e8-4c60-a0aa-a96fd6f69bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_timeframe, y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(x=forecast_timeframe, y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler, actual_start_date, actual_end_date, forecast_start_date, forecast_end_date):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     # Generate timeframes for the x-axis\n",
    "#     actual_timeframe = pd.date_range(actual_start_date, actual_end_date, periods=len(y_test_inv))\n",
    "#     forecast_timeframe = pd.date_range(forecast_start_date, forecast_end_date, periods=len(predictions_inv))\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv, actual_timeframe, forecast_timeframe)\n",
    "\n",
    "# # Adjust the timeframes based on your data\n",
    "# actual_start_date = '2019-04-01'\n",
    "# actual_end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# forecast_end_date = '2025-03-31'\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler, actual_start_date, actual_end_date, forecast_start_date, forecast_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170803f9-39c6-491f-a922-0337cc1d70cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv):\n",
    "#     \"\"\"Plot the actual prices using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.update_layout(title='Stock Price Forecasting', xaxis_title='Time', yaxis_title='Stock Price', legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01))\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "    \n",
    "#     plot_predictions(y_test_inv)\n",
    "\n",
    "# # Assuming y_test is correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53972cec-dae0-42b3-8bc4-183dc4f48c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "#     fig.update_layout(title='Stock Price Forecasting', xaxis_title='Time', yaxis_title='Stock Price', legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01))\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv)\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410150aa-fe40-4614-8d9a-b784135d140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         if data.empty:\n",
    "#             raise ValueError(\"Downloaded data is empty.\")\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     # Summary report\n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering: Add SMA, EMA, and additional lag features\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "#     data['Lag_Close_3'] = data['Close'].shift(3)\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly, side by side.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df314c76-1a49-4fed-9f4d-39c08be1287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message=s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int, scaler: MinMaxScaler):\n",
    "#     \"\"\"Normalize features and create sequences using the specified scaler.\"\"\"\n",
    "#     # Scale the features using the provided scaler\n",
    "#     data_scaled = scaler.transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\"\"\"\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     preprocessed_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e506a-e32f-47ce-acb1-3a3ad1797ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, predictions_inv):\n",
    "#     \"\"\"Plot the actual vs predicted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(y=y_test_inv, mode='lines', name='Actual Prices', line=dict(color='blue')))\n",
    "#     fig.add_trace(go.Scatter(y=predictions_inv, mode='lines', name='Forecast Prices', line=dict(color='red')))\n",
    "#     fig.update_layout(title='Stock Price Forecasting', xaxis_title='Time', yaxis_title='Stock Price', legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01))\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, predictions, scaler):\n",
    "#     \"\"\"Inverse transform and visualize the Forecasting and actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "#     predictions_inv = inverse_transform_single_feature(predictions, scaler, close_index)\n",
    "    \n",
    "#     plot_predictions(y_test_inv, predictions_inv)\n",
    "\n",
    "# # Assuming y_test and predictions are correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, predictions, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235615a-0efc-4a0c-8404-83f6ad3fd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import yfinance as yf\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import logging\n",
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def download_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "#     \"\"\"Downloads stock data from Yahoo Finance.\"\"\"\n",
    "#     try:\n",
    "#         logging.info(f\"Downloading stock data for ticker: {ticker}\")\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "#         if data.empty:\n",
    "#             raise ValueError(\"Downloaded data is empty.\")\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data['Date'] = pd.to_datetime(data['Date'])\n",
    "#         data.set_index('Date', inplace=True)\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to download stock data: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def check_data_quality(data: pd.DataFrame):\n",
    "#     \"\"\"Check for missing values and duplicates.\"\"\"\n",
    "#     null_counts = data.isnull().sum()\n",
    "#     logging.info(f\"Missing values in the dataset:\\n{null_counts[null_counts > 0]}\")\n",
    "    \n",
    "#     duplicate_count = data.duplicated().sum()\n",
    "#     logging.info(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n",
    "    \n",
    "#     # Summary report\n",
    "#     summary_report = f\"Missing Values:\\n{null_counts[null_counts > 0]}\\n\\nDuplicates: {duplicate_count}\"\n",
    "#     logging.info(summary_report)\n",
    "    \n",
    "#     return null_counts[null_counts > 0], duplicate_count\n",
    "\n",
    "# def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "#     \"\"\"Preprocess stock data for LSTM model by adding features and scaling.\"\"\"\n",
    "#     logging.info(\"Preprocessing stock data.\")\n",
    "    \n",
    "#     # Feature Engineering: Add SMA, EMA, and additional lag features\n",
    "#     data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "#     data['Lag_Close_3'] = data['Close'].shift(3)\n",
    "    \n",
    "#     # Forward fill NA values\n",
    "#     data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     # Select features and scale\n",
    "#     features = data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']].values\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "#     logging.info(\"Data preprocessing complete.\")\n",
    "#     return scaled_features, scaler\n",
    "\n",
    "# def visualize_data(data: pd.DataFrame):\n",
    "#     \"\"\"Visualize the 'Close' and 'Open' prices separately with Plotly, side by side.\"\"\"\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=2, subplot_titles=('Close Price', 'Open Price'))\n",
    "    \n",
    "#     # Plot 'Close' price\n",
    "#     trace_close = go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Close Price', line=dict(color='blue'))\n",
    "#     fig.add_trace(trace_close, row=1, col=1)\n",
    "    \n",
    "#     # Plot 'Open' price\n",
    "#     trace_open = go.Scatter(x=data.index, y=data['Open'], mode='lines', name='Open Price', line=dict(color='green'))\n",
    "#     fig.add_trace(trace_open, row=1, col=2)\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Open and Close Prices Over Time',\n",
    "#         xaxis_title='Date',\n",
    "#         yaxis_title='Price',\n",
    "#         showlegend=False\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def main():\n",
    "#     # Example usage\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Check data quality\n",
    "#     nulls, duplicates = check_data_quality(raw_data)\n",
    "    \n",
    "#     # Visualize the raw data\n",
    "#     visualize_data(raw_data)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     scaled_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     logging.info(f\"First 5 scaled values:\\n{scaled_data[:5]}\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f65df3-73e3-43e5-8e56-712bbdb4905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname=s - %(message)s')\n",
    "\n",
    "# def split_data_by_date(data: pd.DataFrame, train_start: str, train_end: str, test_start: str, test_end: str):\n",
    "#     \"\"\"Split data into training and testing sets based on date.\"\"\"\n",
    "#     train_data = data.loc[train_start:train_end]\n",
    "#     test_data = data.loc[test_start:test_end]\n",
    "#     logging.info(\"Data split into training and testing sets based on date.\")\n",
    "#     return train_data, test_data\n",
    "\n",
    "# def prepare_data(data: pd.DataFrame, sequence_length: int, scaler: MinMaxScaler):\n",
    "#     \"\"\"Normalize features and create sequences using the specified scaler.\"\"\"\n",
    "#     # Scale the features using the provided scaler\n",
    "#     data_scaled = scaler.transform(data)\n",
    "    \n",
    "#     X, y = [], []\n",
    "#     for i in range(sequence_length, len(data_scaled)):\n",
    "#         X.append(data_scaled[i-sequence_length:i])\n",
    "#         y.append(data_scaled[i, 0])  # Predicting the 'Close' price\n",
    "#     logging.info(\"Data normalized and sequences created.\")\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# def lstm_data_preparation():\n",
    "#     \"\"\"Main function for data preparation for LSTM.\"\"\"\n",
    "#     ticker_symbol = 'TATAELXSI.NS'\n",
    "#     start_date = '2019-04-01'\n",
    "#     end_date = '2024-03-31'\n",
    "    \n",
    "#     # Download stock data\n",
    "#     raw_data = download_stock_data(ticker_symbol, start_date, end_date)\n",
    "    \n",
    "#     # Preprocess the data\n",
    "#     preprocessed_data, scaler = preprocess_data(raw_data)\n",
    "    \n",
    "#     # Define train and test periods\n",
    "#     train_start, train_end = '2019-04-01', '2023-03-31'\n",
    "#     test_start, test_end = '2023-04-01', '2024-03-31'\n",
    "\n",
    "#     # Split data using the original, unprocessed data\n",
    "#     train_data, test_data = split_data_by_date(raw_data, train_start, train_end, test_start, test_end)\n",
    "\n",
    "#     # Prepare training data\n",
    "#     sequence_length = 60  # Length of the window\n",
    "#     X_train, y_train = prepare_data(train_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     # Prepare testing data\n",
    "#     X_test, y_test = prepare_data(test_data[['Close', 'SMA_10', 'EMA_10', 'Lag_Close_3']], sequence_length, scaler)\n",
    "\n",
    "#     logging.info(\"Training and testing data prepared for LSTM model.\")\n",
    "#     return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# # Run LSTM preparation pipeline\n",
    "# if __name__ == '__main__':\n",
    "#     X_train, X_test, y_train, y_test, scaler = lstm_data_preparation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7a6c5-eb15-4cb6-999b-64a6e27129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# # Assuming X_train, X_test, y_train, y_test have been prepared from Chunk 2\n",
    "# # Train the LSTM model\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "\n",
    "# # Predict on the test data\n",
    "# predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# # Post-processing and visualization\n",
    "# # Assuming y_test and predictions are in the same shape\n",
    "# def inverse_transform_single_feature(data, scaler, index):\n",
    "#     \"\"\"Inverse transform a single feature using the scaler's parameters.\"\"\"\n",
    "#     single_feature_data = np.zeros((data.shape[0], len(scaler.min_)))\n",
    "#     single_feature_data[:, index] = data.reshape(-1)\n",
    "#     inversed_data = scaler.inverse_transform(single_feature_data)\n",
    "#     return inversed_data[:, index]\n",
    "\n",
    "# def plot_predictions(y_test_inv, actual_dates):\n",
    "#     \"\"\"Plot the actual prices using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_dates, y=y_test_inv, mode='lines', name='Actual Stock Price', line=dict(color='blue')))\n",
    "#     fig.update_layout(\n",
    "#         title='Actual Stock Price',\n",
    "#         xaxis_title='Time',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "\n",
    "# def postprocess_and_visualize(y_test, scaler, start_date, end_date):\n",
    "#     \"\"\"Inverse transform and visualize the actual data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "    \n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "    \n",
    "#     # Generate a date range for the x-axis\n",
    "#     actual_dates = pd.date_range(start_date, end_date, periods=len(y_test_inv))\n",
    "    \n",
    "#     plot_predictions(y_test_inv, actual_dates)\n",
    "\n",
    "# # Define the time range based on your data\n",
    "# start_date = '2019-04-01'\n",
    "# end_date = '2023-03-31'\n",
    "\n",
    "# # Assuming y_test is correctly shaped for the above function\n",
    "# postprocess_and_visualize(y_test, scaler, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3be3d-c0f6-43fd-bb7a-4ea8676517aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import plotly.graph_objs as go\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, X_val=None, y_val=None, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     if X_val is not None and y_val is not None:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#     else:\n",
    "#         history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "#     return model, history\n",
    "\n",
    "# def prepare_forecast_input(X_train, last_observations, time_steps):\n",
    "#     \"\"\"Prepare input for forecasting based on the last observations.\"\"\"\n",
    "#     # Reshape to the correct input format for LSTM\n",
    "#     input_data = last_observations.reshape((1, time_steps, X_train.shape[2]))\n",
    "#     return input_data\n",
    "\n",
    "# def forecast_lstm(model, X_train, n_steps, scaler):\n",
    "#     \"\"\"Forecast future stock prices using the trained LSTM model.\"\"\"\n",
    "#     predictions = []\n",
    "#     last_observations = X_train[-1]\n",
    "\n",
    "#     for _ in range(n_steps):\n",
    "#         # Prepare input and predict the next value\n",
    "#         input_data = prepare_forecast_input(X_train, last_observations, X_train.shape[1])\n",
    "#         prediction = model.predict(input_data)[0, 0]\n",
    "\n",
    "#         # Prepare array to hold the predicted value and fill missing columns with zeros\n",
    "#         predicted_row = np.zeros((1, scaler.scale_.shape[0]))\n",
    "#         predicted_row[0, 0] = prediction\n",
    "\n",
    "#         # Inverse transform the predicted value and store it\n",
    "#         predicted_value = scaler.inverse_transform(predicted_row)[0, 0]\n",
    "#         predictions.append(predicted_value)\n",
    "\n",
    "#         # Update the last_observations for the next prediction\n",
    "#         last_observations = np.roll(last_observations, -1)\n",
    "#         last_observations[-1, 0] = prediction\n",
    "\n",
    "#     return predictions\n",
    "\n",
    "# def plot_predictions(y_test_inv, actual_dates, forecast_dates=None, forecasted_values=None):\n",
    "#     \"\"\"Plot the actual prices and optionally forecasted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_dates, y=y_test_inv, mode='lines', name='Actual Stock Price', line=dict(color='blue')))\n",
    "    \n",
    "#     if forecast_dates is not None and forecasted_values is not None:\n",
    "#         fig.add_trace(go.Scatter(x=forecast_dates, y=forecasted_values, mode='lines', name='Forecasted Stock Price', line=dict(color='red')))\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Time',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, scaler, start_date, end_date, forecast_start_date, n_months_forecast, model, X_train):\n",
    "#     \"\"\"Inverse transform and visualize the actual and forecasted data.\"\"\"\n",
    "#     close_index = 0  # Assume 'Close' is the first column in the features\n",
    "\n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     y_test_inv = inverse_transform_single_feature(y_test, scaler, close_index)\n",
    "\n",
    "#     # Generate a date range for the x-axis\n",
    "#     actual_dates = pd.date_range(start_date, end_date, periods=len(y_test_inv))\n",
    "\n",
    "#     # Forecast future values\n",
    "#     forecasted_values = forecast_lstm(model, X_train, n_months_forecast, scaler)\n",
    "#     forecast_dates = pd.date_range(forecast_start_date, periods=n_months_forecast, freq='M')\n",
    "    \n",
    "#     # Plot actual and forecasted prices\n",
    "#     plot_predictions(y_test_inv, actual_dates, forecast_dates, forecasted_values)\n",
    "\n",
    "# # Define the time range based on your data\n",
    "# actual_start_date = '2019-04-01'\n",
    "# actual_end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# n_months_forecast = 12\n",
    "\n",
    "# # Assuming X_train, y_test, and scaler are already prepared\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "# postprocess_and_visualize(y_test, scaler, actual_start_date, actual_end_date, forecast_start_date, n_months_forecast, lstm_model, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b333df-05b4-4f68-bc18-d2df54992887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# # Define the LSTM model\n",
    "# def build_lstm_model(input_shape):\n",
    "#     \"\"\"Builds an LSTM model for stock price prediction.\"\"\"\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(50, return_sequences=False))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(1))  # Predicting a single value: the next day's price\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#     return model\n",
    "\n",
    "# # Train the LSTM model\n",
    "# def train_lstm_model(X_train, y_train, epochs=20, batch_size=32):\n",
    "#     \"\"\"Trains the LSTM model with the provided training data.\"\"\"\n",
    "#     model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "#     history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "#     return model, history\n",
    "\n",
    "# def prepare_forecast_input(X_train, last_observations):\n",
    "#     \"\"\"Prepare input for forecasting based on the last observations.\"\"\"\n",
    "#     # Reshape to the correct input format for LSTM\n",
    "#     return last_observations.reshape((1, X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# def forecast_lstm(model, X_train, n_steps, scaler):\n",
    "#     \"\"\"Forecast future stock prices using the trained LSTM model.\"\"\"\n",
    "#     predictions = []\n",
    "#     last_observations = X_train[-1]\n",
    "\n",
    "#     for _ in range(n_steps):\n",
    "#         # Prepare input and predict the next value\n",
    "#         input_data = prepare_forecast_input(X_train, last_observations)\n",
    "#         prediction = model.predict(input_data)[0, 0]\n",
    "\n",
    "#         # Inverse transform to get the predicted value\n",
    "#         predicted_row = np.zeros((1, scaler.scale_.shape[0]))\n",
    "#         predicted_row[0, 0] = prediction\n",
    "#         predicted_value = scaler.inverse_transform(predicted_row)[0, 0]\n",
    "#         predictions.append(predicted_value)\n",
    "\n",
    "#         # Update the last observations for the next prediction\n",
    "#         last_observations = np.roll(last_observations, -1)\n",
    "#         last_observations[-1, 0] = prediction\n",
    "\n",
    "#     return predictions\n",
    "\n",
    "# def plot_predictions(actual_values, actual_dates, forecast_dates=None, forecasted_values=None):\n",
    "#     \"\"\"Plot the actual prices and optionally forecasted values using Plotly.\"\"\"\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=actual_dates, y=actual_values, mode='lines', name='Actual Stock Price', line=dict(color='blue')))\n",
    "    \n",
    "#     if forecast_dates is not None and forecasted_values is not None:\n",
    "#         fig.add_trace(go.Scatter(x=forecast_dates, y=forecasted_values, mode='lines', name='Forecasted Stock Price', line=dict(color='red')))\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         title='Stock Price Forecasting',\n",
    "#         xaxis_title='Time',\n",
    "#         yaxis_title='Stock Price',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "#     fig.show()\n",
    "\n",
    "# def postprocess_and_visualize(y_test, scaler, start_date, end_date, forecast_start_date, n_months_forecast, model, X_train):\n",
    "#     \"\"\"Inverse transform and visualize the actual and forecasted data.\"\"\"\n",
    "#     # Inverse transform only the 'Close' column\n",
    "#     actual_values = inverse_transform_single_feature(y_test, scaler, 0)\n",
    "\n",
    "#     # Generate a date range for the x-axis\n",
    "#     actual_dates = pd.date_range(start_date, end_date, periods=len(actual_values))\n",
    "\n",
    "#     # Forecast future values\n",
    "#     forecasted_values = forecast_lstm(model, X_train, n_months_forecast, scaler)\n",
    "#     forecast_dates = pd.date_range(forecast_start_date, periods=n_months_forecast, freq='M')\n",
    "    \n",
    "#     # Plot actual and forecasted prices\n",
    "#     plot_predictions(actual_values, actual_dates, forecast_dates, forecasted_values)\n",
    "\n",
    "# # Adjust the timeframes based on your data\n",
    "# actual_start_date = '2019-04-01'\n",
    "# actual_end_date = '2023-03-31'\n",
    "# forecast_start_date = '2024-04-01'\n",
    "# n_months_forecast = 12\n",
    "\n",
    "# # Assuming X_train, y_test, and scaler are already prepared\n",
    "# lstm_model, lstm_history = train_lstm_model(X_train, y_train, epochs=64, batch_size=128)\n",
    "# postprocess_and_visualize(y_test, scaler, actual_start_date, actual_end_date, forecast_start_date, n_months_forecast, lstm_model, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40e2a2-0080-4650-9e73-32a6f1a87726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7a0ea-6cea-4e23-b4d2-587faeae926f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27dfea-ecdb-418b-95c2-102522b19152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
